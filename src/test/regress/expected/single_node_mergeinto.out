drop table if exists row_ddl;
NOTICE:  table "row_ddl" does not exist, skipping
drop table if exists col_ddl;
NOTICE:  table "col_ddl" does not exist, skipping
create table row_ddl 
(c1 int not null, 
c2 varchar(200) not null, 
c3 date default '2018-06-14', 
c4 varchar(200) default '空的就用这个default', 
c5 numeric(18,9) default 123456.000000009 check (c5>0), 
c6 text default 'comments for row');
create table col_ddl
(c1 int not null, 
c2 varchar(200) not null, 
c3 date default '2018-06-14', 
c4 varchar(200) default '空的就用这个default', 
c5 numeric(18,9) default 123456.000000009 , 
c6 text default 'comments for col');
insert into row_ddl values(generate_series(1,10),'A'||(generate_series(1,10))||'Z', date'2000-03-01'+generate_series(1,10), 'c'||generate_series(1,10)||'我的２００４');
insert into col_ddl values(generate_series(11,20),'A'||(generate_series(11,20))||'Z', date'2000-03-01'+generate_series(11,20), 'c'||generate_series(11,20)||'我的２００４');
alter table row_ddl drop column c5;
alter table row_ddl add column c5 int default 10;
alter table col_ddl drop column c2;
alter table col_ddl add column c2 int;
merge into col_ddl t1 using row_ddl t2 on t1.c1=t2.c1
when matched then update set t1.c6=t1.c6||t2.c6,c3=t2.c3+interval '1' day
when not matched then insert values(t2.c1,t2.c3,t2.c4,t2.c5,t2.c6,length(t2.c2));
drop table if exists row_ddl;
drop table if exists col_ddl;
create table row_ddl 
(c1 int not null, 
c2 varchar(200) not null, 
c3 date default '2018-06-14', 
c4 varchar(200) default '空的就用这个default', 
c5 numeric(18,9) default 123456.000000009 check (c5>0), 
c6 text default 'comments for row');
create table col_ddl
(c1 int not null, 
c2 varchar(200) not null, 
c3 date default '2018-06-14', 
c4 varchar(200) default '空的就用这个default', 
c5 numeric(18,9) default 123456.000000009 , 
c6 text default 'comments for col');
--表上建立索引
create index i_row_ddl on row_ddl(c4,c2)local;
ERROR:  non-partitioned table does not support local partitioned indexes 
create index i_col_ddl on col_ddl(c1,c3)local;
ERROR:  non-partitioned table does not support local partitioned indexes 
insert into row_ddl values(generate_series(1,10),'A'||(generate_series(1,10))||'Z', date'2000-03-01'+generate_series(1,10), 'c'||generate_series(1,10)||'我的２００４');
insert into col_ddl values(generate_series(11,20),'A'||(generate_series(11,20))||'Z', date'2000-03-01'+generate_series(11,20), 'c'||generate_series(11,20)||'我的２００４');
alter table row_ddl drop column c5;
alter table row_ddl add column c5 int default 10;
alter table col_ddl drop column c2;
alter table col_ddl add column c2 int;
alter table row_ddl drop column c3;
alter table row_ddl add column c3 bool default 't';
merge into row_ddl t1 using col_ddl t2 on t1.c1=t2.c1
when matched then update set t1.c6=t2.c6, t1.c3=case when t2.c3> date'2000-03-02' then 0 else 1 end
when not matched then insert(c1,c4,c5,c6) values(t2.c1,t2.c4,t2.c5,t2.c6);
ERROR:  null value in column "c2" violates not-null constraint
DETAIL:  Failing row contains (11, null, c11我的２００４, comments for col, 123456, t).
drop table if exists row_dml;
NOTICE:  table "row_dml" does not exist, skipping
drop table if exists col_dml;
NOTICE:  table "col_dml" does not exist, skipping
create temp table row_dml 
(c1 int not null, 
c2 varchar(200) not null, 
c3 date default '2018-06-14', 
c4 varchar(200) default '空的就用这个default', 
c5 numeric(18,9) default 123456.000000009 check (c5>0), 
c6 text default 'comments',
unique(c2,c4));
NOTICE:  CREATE TABLE / UNIQUE will create implicit index "row_dml_c2_c4_key" for table "row_dml"
create unlogged table col_dml
(c1 int not null, 
c2 varchar(200) not null, 
c3 date default '2018-06-14', 
c4 varchar(200) default '空的就用这个default', 
c5 numeric(18,9) default 123456.000000009 , 
c6 text default 'comments');
create table web_page
(
wp_web_page_sk            integer               not null,
wp_web_page_id            char(16)              not null,
wp_rec_start_date         date                          ,
wp_rec_end_date           date                          ,
wp_creation_date_sk       integer                       ,
wp_access_date_sk         integer                       ,
wp_autogen_flag           char(1)                       ,
wp_customer_sk            integer                       ,
wp_url                    varchar(100)                  ,
wp_type                   char(50)                      ,
wp_char_count             integer                       ,
wp_link_count             integer                       ,
wp_image_count            integer                       ,
wp_max_ad_count           integer                       
 );
 
--表上建立索引
insert into row_dml values(generate_series(1,100),'A'||(generate_series(1,100))||'Z', date'2000-03-01'+generate_series(1,100), 'c'||generate_series(1,100)||'我的２００４');
insert into col_dml select * from row_dml;
copy web_page from STDIN (DELIMITER ',');
merge into row_dml t1 using
(
select coalesce(wp_type, wp_web_page_id) c6,
wp_type c1,
nvl(wp_rec_start_date, wp_rec_end_date) c2 ,
length(nullif(wp_type,wp_web_page_id)) c5
from web_page ) t2
on ( t1.c1=t2.c5+50 )
when matched then update set t1.c6 = t2.c6
when not matched then insert values(t2.c5, t2.c6, t2.c2);
ERROR:  unable to get a stable set of rows in the source tables
-------------------------------------------------------
-- Verify foreign key validity
-- Notice: merge into  when matched then update [FK] when not matched then insert values(value, [FK]);
--         we must take attention about column in "[]";
-------------------------------------------------------
create table pkt(a int primary key);
NOTICE:  CREATE TABLE / PRIMARY KEY will create implicit index "pkt_pkey" for table "pkt"
create table fkt(a int primary key, b int references pkt);
NOTICE:  CREATE TABLE / PRIMARY KEY will create implicit index "fkt_pkey" for table "fkt"
create table dtt(a int, b int);
insert into pkt values(1),(2),(3);
insert into dtt values(1,1),(2,2);
merge into fkt using dtt on (dtt.a=fkt.a) when matched then update set fkt.b = 3 when not matched then insert values(dtt.a, dtt.b);
select * from fkt;
 a | b 
---+---
 1 | 1
 2 | 2
(2 rows)

merge into fkt using dtt on (dtt.a=fkt.a) when matched then update set fkt.b = 3 when not matched then insert values(dtt.a, dtt.b);
select * from fkt;
 a | b 
---+---
 1 | 3
 2 | 3
(2 rows)

merge into fkt using dtt on (dtt.a=fkt.a) when matched then update set fkt.b = 5 when not matched then insert values(dtt.a, dtt.b);
ERROR:  insert or update on table "fkt" violates foreign key constraint "fkt_b_fkey"
DETAIL:  Key (b)=(5) is not present in table "pkt".
select * from fkt;
 a | b 
---+---
 1 | 3
 2 | 3
(2 rows)

truncate fkt;
insert into dtt values(5,5);
merge into fkt using dtt on (dtt.a=fkt.a) when matched then update set fkt.b = 3 when not matched then insert values(dtt.a, dtt.b);
ERROR:  insert or update on table "fkt" violates foreign key constraint "fkt_b_fkey"
DETAIL:  Key (b)=(5) is not present in table "pkt".
select * from fkt;
 a | b 
---+---
(0 rows)

----------------------------------------------------
-- trigger
----------------------------------------------------
CREATE FUNCTION mgit_before_func()
  RETURNS TRIGGER language plpgsql AS
$$
BEGIN
  IF (TG_OP = 'UPDATE') THEN
    RAISE warning 'before update (old): %', old.*::TEXT;
    RAISE warning 'before update (new): %', new.*::TEXT;
  elsIF (TG_OP = 'INSERT') THEN
    RAISE warning 'before insert (new): %', new.*::TEXT;
  END IF;
  RETURN new;
END;
$$;
CREATE TRIGGER mgit_before_trig BEFORE INSERT OR UPDATE ON fkt
  FOR EACH ROW EXECUTE procedure mgit_before_func();
CREATE FUNCTION mgit_after_func()
  RETURNS TRIGGER language plpgsql AS
$$
BEGIN
  IF (TG_OP = 'UPDATE') THEN
    RAISE warning 'after update (old): %', old.*::TEXT;
    RAISE warning 'after update (new): %', new.*::TEXT;
  elsIF (TG_OP = 'INSERT') THEN
    RAISE warning 'after insert (new): %', new.*::TEXT;
  END IF;
  RETURN null;
END;
$$;
CREATE TRIGGER mgit_after_trig AFTER INSERT OR UPDATE ON fkt
  FOR EACH ROW EXECUTE procedure mgit_after_func();
insert into fkt values(1,1);
WARNING:  before insert (new): (1,1)
WARNING:  after insert (new): (1,1)
delete from dtt where a = 5; -- now dtt: (1,1),(2,2)  fkt:(1,1)
merge into fkt using dtt on (dtt.a=fkt.a) when matched then update set fkt.b = 3 when not matched then insert values(dtt.a, dtt.b);
WARNING:  before update (old): (1,1)
WARNING:  before update (new): (1,3)
WARNING:  before insert (new): (2,2)
WARNING:  after update (old): (1,1)
WARNING:  after update (new): (1,3)
WARNING:  after insert (new): (2,2)
select * from fkt;
 a | b 
---+---
 1 | 3
 2 | 2
(2 rows)

-- test for merge with where clauses
create table explain_t1 (a int, b int);
create table explain_t2 (f1 int, f2 int);
explain (verbose on, costs off) merge into explain_t1
    using explain_t2 tt2 on explain_t1.a = tt2.f1
when not matched then
    insert values(1,3) where tt2.f1 = 1;
                                      QUERY PLAN                                       
---------------------------------------------------------------------------------------
 Merge on public.explain_t1
   Insert Cond: (tt2.f1 = 1)
   ->  Hash Left Join
         Output: tt2.f1, tt2.f2, explain_t1.a, explain_t1.b, explain_t1.ctid, tt2.ctid
         Hash Cond: (tt2.f1 = explain_t1.a)
         ->  Seq Scan on public.explain_t2 tt2
               Output: tt2.f1, tt2.f2, tt2.ctid
         ->  Hash
               Output: explain_t1.a, explain_t1.b, explain_t1.ctid
               ->  Seq Scan on public.explain_t1
                     Output: explain_t1.a, explain_t1.b, explain_t1.ctid
(11 rows)

explain (verbose on, costs off) merge into explain_t1
    using explain_t2 tt2 on explain_t1.a = tt2.f1
when matched then
    update set b = 10 where explain_t1.a = 1;
                                      QUERY PLAN                                       
---------------------------------------------------------------------------------------
 Merge on public.explain_t1
   Update Cond: (explain_t1.a = 1)
   ->  Hash Join
         Output: tt2.f1, tt2.f2, explain_t1.a, explain_t1.b, explain_t1.ctid, tt2.ctid
         Hash Cond: (explain_t1.a = tt2.f1)
         ->  Seq Scan on public.explain_t1
               Output: explain_t1.a, explain_t1.b, explain_t1.ctid
         ->  Hash
               Output: tt2.f1, tt2.f2, tt2.ctid
               ->  Seq Scan on public.explain_t2 tt2
                     Output: tt2.f1, tt2.f2, tt2.ctid
(11 rows)

explain (verbose on, costs off) merge into explain_t1
    using explain_t2 tt2 on explain_t1.a = tt2.f1
when matched then
    update set b = 10 where explain_t1.a = 1
when not matched then
    insert values(1,3) where tt2.f1 = 1;
                                      QUERY PLAN                                       
---------------------------------------------------------------------------------------
 Merge on public.explain_t1
   Update Cond: (explain_t1.a = 1)
   Insert Cond: (tt2.f1 = 1)
   ->  Hash Left Join
         Output: tt2.f1, tt2.f2, explain_t1.a, explain_t1.b, explain_t1.ctid, tt2.ctid
         Hash Cond: (tt2.f1 = explain_t1.a)
         ->  Seq Scan on public.explain_t2 tt2
               Output: tt2.f1, tt2.f2, tt2.ctid
         ->  Hash
               Output: explain_t1.a, explain_t1.b, explain_t1.ctid
               ->  Seq Scan on public.explain_t1
                     Output: explain_t1.a, explain_t1.b, explain_t1.ctid
(12 rows)

explain (verbose on, costs off) merge into explain_t1
    using explain_t2 tt2 on explain_t1.a = tt2.f1
when matched then
    update set b = 10 where tt2.f2 = 1;
                                      QUERY PLAN                                       
---------------------------------------------------------------------------------------
 Merge on public.explain_t1
   Update Cond: (tt2.f2 = 1)
   ->  Hash Join
         Output: tt2.f1, tt2.f2, explain_t1.a, explain_t1.b, explain_t1.ctid, tt2.ctid
         Hash Cond: (explain_t1.a = tt2.f1)
         ->  Seq Scan on public.explain_t1
               Output: explain_t1.a, explain_t1.b, explain_t1.ctid
         ->  Hash
               Output: tt2.f1, tt2.f2, tt2.ctid
               ->  Seq Scan on public.explain_t2 tt2
                     Output: tt2.f1, tt2.f2, tt2.ctid
(11 rows)

-- duplicate alias on source table
explain (verbose on, costs off) merge into explain_t2 t2 using (
  select
    t1.a,
    t1.b,
    t1.a aa,
    t1.b bb
  from
    explain_t1 t1
) tmp on (t2.f1 = tmp.b)
when matched THEN
    update
    set
      t2.f2 = tmp.aa
    where
      t2.f1 = tmp.bb;
                               QUERY PLAN                               
------------------------------------------------------------------------
 Merge on public.explain_t2 t2
   Update Cond: (t2.f1 = tmp.bb)
   ->  Hash Join
         Output: t1.a, t1.b, t1.a, t1.b, t2.f1, t2.f2, t2.ctid, t1.ctid
         Hash Cond: (t2.f1 = t1.b)
         ->  Seq Scan on public.explain_t2 t2
               Output: t2.f1, t2.f2, t2.ctid
         ->  Hash
               Output: t1.a, t1.b, t1.ctid
               ->  Seq Scan on public.explain_t1 t1
                     Output: t1.a, t1.b, t1.ctid
(11 rows)

explain (verbose on, costs off) merge /*+ leading((t2 t1)) */ into explain_t2 t2 using (
  select
    t1.a,
    t1.b,
    t1.a aa,
    t1.b bb
  from
    explain_t1 t1
) tmp on (t2.f1 = tmp.b)
when not matched THEN
  insert values(1,3) where tmp.bb = 1;
                               QUERY PLAN                               
------------------------------------------------------------------------
 Merge on public.explain_t2 t2
   Insert Cond: (tmp.bb = 1)
   ->  Hash Right Join
         Output: t1.a, t1.b, t1.a, t1.b, t2.f1, t2.f2, t2.ctid, t1.ctid
         Hash Cond: (t2.f1 = t1.b)
         ->  Seq Scan on public.explain_t2 t2
               Output: t2.f1, t2.f2, t2.ctid
         ->  Hash
               Output: t1.a, t1.b, t1.ctid
               ->  Seq Scan on public.explain_t1 t1
                     Output: t1.a, t1.b, t1.ctid
(11 rows)

explain (verbose on, costs off) merge /*+ leading((t1 t2)) */ into explain_t2 t2 using (
  select
    t1.a,
    t1.b,
    t1.a aa,
    t1.b bb
  from
    explain_t1 t1
) tmp on (t2.f1 = tmp.b)
when not matched THEN
  insert values(1,3) where tmp.bb = 1;
                               QUERY PLAN                               
------------------------------------------------------------------------
 Merge on public.explain_t2 t2
   Insert Cond: (tmp.bb = 1)
   ->  Hash Left Join
         Output: t1.a, t1.b, t1.a, t1.b, t2.f1, t2.f2, t2.ctid, t1.ctid
         Hash Cond: (t1.b = t2.f1)
         ->  Seq Scan on public.explain_t1 t1
               Output: t1.a, t1.b, t1.ctid
         ->  Hash
               Output: t2.f1, t2.f2, t2.ctid
               ->  Seq Scan on public.explain_t2 t2
                     Output: t2.f1, t2.f2, t2.ctid
(11 rows)

--test using caluse is one time fiter result
create schema bmsql_schema;
set current_schema to bmsql_schema;
CREATE TABLE bmsql_history (
    hist_id int4,
    h_c_id int4,
    h_c_d_id int4,
    h_c_w_id int4,
    h_d_id int4,
    h_w_id int4,
    h_date timestamp(6),
    h_amount numeric(6, 2),
    h_data varchar(24)
);
CREATE TABLE bmsql_customer (
    c_w_id int4 NOT NULL default 1,
    c_d_id int4 NOT NULL default 2,
    c_id int4 NOT NULL default 3,
    c_discount numeric(4, 4),
    c_credit bpchar(2),
    c_last varchar(16),
    c_first varchar(16),
    c_credit_lim numeric(12, 2),
    c_balance numeric(12, 2),
    c_ytd_payment numeric(12, 2),
    c_payment_cnt int4,
    c_delivery_cnt int4,
    c_street_1 varchar(20),
    c_street_2 varchar(20),
    c_city varchar(20),
    c_state bpchar(2),
    c_zip bpchar(9),
    c_phone bpchar(16),
    c_since timestamp(6),
    lc_middle bpchar(2),
    c_data varchar(500),
    CONSTRAINT bmsql_customer_pkey PRIMARY KEY (c_w_id, c_d_id, c_id)
);
NOTICE:  CREATE TABLE / PRIMARY KEY will create implicit index "bmsql_customer_pkey" for table "bmsql_customer"
CREATE INDEX bmsql_customer_idx1 ON bmsql_customer (c_w_id, c_d_id, c_last, c_first);
CREATE TABLE bmsql_district (
    d_w_id int4 NOT NULL,
    d_id int4 NOT NULL,
    d_ytd numeric(12, 2),
    d_tax numeric(4, 4),
    d_next_o_id int4,
    d_name varchar(10),
    d_street_1 varchar(20),
    d_street_2 varchar(20),
    d_city varchar(20),
    d_state bpchar(2),
    d_zip bpchar(9),
    cONSTRAINT bmsq1_district_pkey PRIMARY KEY (d_w_id, d_id)
);
NOTICE:  CREATE TABLE / PRIMARY KEY will create implicit index "bmsq1_district_pkey" for table "bmsql_district"
CREATE TABLE bmsql_item (
    i_id int4 NoT NULL,
    i_name varchar(24),
    i_price numeric(5, 2),
    i_data varchar(50),
    i_im_id int4
);
create view bmsql_b_view as (
    select
        c_w_id,
        c_balance,
        c_last
    from
        bmsql_customer
        inner join bmsql_district on bmsql_customer.c_w_id != bmsql_district.d_id
    union
    select
        *
    from
        (
            select
                count(*),
                i_price,
                i_name
            from
                bmsql_item
            group by
                i_price,
                i_name
        ) alias1
);
CREATE TABLE bmsql_new_order (
    no_w_id int4,
    no_d_id int4,
    no_o_id int4
);
CREATE TABLE bmsql_oorder (
    o_w_id int4 NOT NULL default 1,
    o_d_id int4 NOT NULL default 2,
    o_id int4 NOT NULL default 3,
    o_c_id int4,
    o_carrier_id int4,
    o_ol_cnt int4,
    o_ali_local int4,
    o_entry_d timestamp(6),
    CONSTRAINT bmsql_oorder_pkey PRIMARY KEY (o_w_id, o_d_id, o_id)
);
NOTICE:  CREATE TABLE / PRIMARY KEY will create implicit index "bmsql_oorder_pkey" for table "bmsql_oorder"
CREATE TABLE bmsql_config (
    cfg_name varchar(30) NOT NULL,
    cfg_value varchar(50)
);
explain (costs off) MERGE INTO bmsql_history AS alias1 USING (
    select d_w_id alias3 from bmsql_district where 1<1
) AS alias2 ON alias1.h_c_w_id <= alias2.alias3
WHEN MATCHED THEN
UPDATE
SET alias1.h_w_id = 1
WHERE alias3 != 30002;
               QUERY PLAN                
-----------------------------------------
 Merge on bmsql_history alias1
   Update Cond: (alias2.alias3 <> 30002)
   ->  Result
         One-Time Filter: false
(4 rows)

MERGE INTO bmsql_history AS alias1 USING (
    select d_w_id alias3 from bmsql_district where 1<1
) AS alias2 ON alias1.h_c_w_id <= alias2.alias3
WHEN MATCHED THEN
UPDATE
SET alias1.h_w_id = 1
WHERE alias3 != 30002;
explain(costs off) MERGE INTO bmsql_history AS alias1 USING (
    SELECT
        count(bmsql_b_view.c_last) AS alias1,
        CEIL(count(bmsql_district.d_zip)) alias2,
        min(bmsql_district.d_w_id) alias3,
        count(bmsql_district.d_zip) AS alias4,
        pg_client_encoding() AS alias5
    FROM
        bmsql_b_view
        RIGHT JOIN ONLY bmsql_new_order ON bmsql_b_view.c_balance >= bmsql_new_order.no_d_id,
        ONLY bmsql_district
    WHERE
        bmsql_district.d_name <= substring(
            'xx'
            FROM
                1 FOR 10
        )
        AND rownum < 3
    GROUP BY
        bmsql_new_order.no_w_id
    HAVING
        pg_client_encoding() < pg_client_encoding()
    ORDER BY
        alias3 DESC NULLS FIRST offset 2
    FETCH FIRST
        ROW ONLY
) AS alias2 ON alias1.h_c_w_id <= alias2.alias3
WHEN MATCHED THEN
UPDATE
SET
    alias1.h_w_id =(
        SELECT
            octet_length(quote_literal(bmsql_config.cfg_value)) alias2
        FROM
            bmsql_new_order alias1,
            bmsql_history
            LEFT JOIN bmsql_config ON initcap(bmsql_history.h_data) <= to_char(
                nvl(bmsql_config.cfg_name, bmsql_config.cfg_value)
            )
        GROUP BY
            bmsql_config.cfg_value
        ORDER BY
            alias2 NULLS FIRST
        LIMIT
            1
    )
WHERE
    alias1.h_c_w_id >= alias1.h_amount
    OR alias3 != 30002;
                                                                        QUERY PLAN                                                                         
-----------------------------------------------------------------------------------------------------------------------------------------------------------
 Merge on bmsql_history alias1
   Update Cond: (((alias1.h_c_w_id)::numeric >= alias1.h_amount) OR (alias2.alias3 <> 30002))
   InitPlan 1 (returns $0)
     ->  Limit
           ->  Sort
                 Sort Key: (octet_length(quote_literal((bmsql_config.cfg_value)::text))) NULLS FIRST
                 ->  HashAggregate
                       Group By Key: bmsql_config.cfg_value
                       ->  Nested Loop
                             ->  Nested Loop Left Join
                                   Join Filter: (initcap((bmsql_history.h_data)::text) <= (COALESCE(bmsql_config.cfg_name, bmsql_config.cfg_value))::text)
                                   ->  Seq Scan on bmsql_history
                                   ->  Materialize
                                         ->  Seq Scan on bmsql_config
                             ->  Materialize
                                   ->  Seq Scan on bmsql_new_order alias1
   ->  Result
         One-Time Filter: false
(18 rows)

MERGE INTO bmsql_history AS alias1 USING (
    SELECT
        count(bmsql_b_view.c_last) AS alias1,
        CEIL(count(bmsql_district.d_zip)) alias2,
        min(bmsql_district.d_w_id) alias3,
        count(bmsql_district.d_zip) AS alias4,
        pg_client_encoding() AS alias5
    FROM
        bmsql_b_view
        RIGHT JOIN ONLY bmsql_new_order ON bmsql_b_view.c_balance >= bmsql_new_order.no_d_id,
        ONLY bmsql_district
    WHERE
        bmsql_district.d_name <= substring(
            'xx'
            FROM
                1 FOR 10
        )
        AND rownum < 3
    GROUP BY
        bmsql_new_order.no_w_id
    HAVING
        pg_client_encoding() < pg_client_encoding()
    ORDER BY
        alias3 DESC NULLS FIRST offset 2
    FETCH FIRST
        ROW ONLY
) AS alias2 ON alias1.h_c_w_id <= alias2.alias3
WHEN MATCHED THEN
UPDATE
SET
    alias1.h_w_id =(
        SELECT
            octet_length(quote_literal(bmsql_config.cfg_value)) alias2
        FROM
            bmsql_new_order alias1,
            bmsql_history
            LEFT JOIN bmsql_config ON initcap(bmsql_history.h_data) <= to_char(
                nvl(bmsql_config.cfg_name, bmsql_config.cfg_value)
            )
        GROUP BY
            bmsql_config.cfg_value
        ORDER BY
            alias2 NULLS FIRST
        LIMIT
            1
    )
WHERE
    alias1.h_c_w_id >= alias1.h_amount
    OR alias3 != 30002;
CREATE TABLE products
(
product_id INTEGER,
product_name VARCHAR2(60),
category VARCHAR2(60)
);
INSERT INTO products VALUES (1501, 'vivitar 35mm', 'electrncs');
INSERT INTO products VALUES (1502, 'olympus is50', 'electrncs');
INSERT INTO products VALUES (1600, 'play gym', 'toys');
INSERT INTO products VALUES (1601, 'lamaze', 'toys');
INSERT INTO products VALUES (1666, 'harry potter', 'dvd');
MERGE INTO products vp
USING products np
ON (vp.product_id = np.product_id)
WHEN MATCHED THEN
UPDATE SET vp.product_name = np.product_name, vp.category = np.category WHERE vp.product_name != 'play gym'
WHEN NOT MATCHED THEN
INSERT VALUES (np.product_id, np.product_name, np.category) WHERE np.category = 'books';
select * from products order by 1;
 product_id | product_name | category  
------------+--------------+-----------
       1501 | vivitar 35mm | electrncs
       1502 | olympus is50 | electrncs
       1600 | play gym     | toys
       1601 | lamaze       | toys
       1666 | harry potter | dvd
(5 rows)

MERGE INTO products vp
USING products np
ON (vp.product_id = np.product_id)
WHEN MATCHED THEN
UPDATE SET vp.product_name = np.category, vp.category = np.product_name WHERE vp.product_name != 'play gym'
WHEN NOT MATCHED THEN
INSERT VALUES (np.product_id, np.product_name, np.category) WHERE np.category = 'books';
select * from products order by 1;
 product_id | product_name |   category   
------------+--------------+--------------
       1501 | electrncs    | vivitar 35mm
       1502 | electrncs    | olympus is50
       1600 | play gym     | toys
       1601 | toys         | lamaze
       1666 | dvd          | harry potter
(5 rows)

drop table products;
reset current_schema;
------------------------------------------------
-- clean up
------------------------------------------------
drop schema bmsql_schema cascade;
NOTICE:  drop cascades to 8 other objects
DETAIL:  drop cascades to table bmsql_schema.bmsql_history
drop cascades to table bmsql_schema.bmsql_customer
drop cascades to table bmsql_schema.bmsql_district
drop cascades to table bmsql_schema.bmsql_item
drop cascades to view bmsql_schema.bmsql_b_view
drop cascades to table bmsql_schema.bmsql_new_order
drop cascades to table bmsql_schema.bmsql_oorder
drop cascades to table bmsql_schema.bmsql_config
drop trigger mgit_after_trig on fkt;
drop trigger mgit_before_trig on fkt;
drop function mgit_before_func;
drop function mgit_after_func;
drop table dtt;
drop table fkt;
drop table pkt;
